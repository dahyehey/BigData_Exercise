{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee8222b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"myApp\")\\\n",
    "    .config(conf=myConf)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d0458",
   "metadata": {},
   "source": [
    "## 문제: 서울시 지하철 호선별 역별 유/무임 승하차 인원 분석\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b904e",
   "metadata": {},
   "source": [
    "* (1-1) '서울시 지하철 호선별 역별 유_무임 승하차 인원 정보.csv'를 데이터프레임으로 읽고, 스키마를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9958852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "myDf = spark\\\n",
    "            .read.option(\"charset\", \"euc-kr\")\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"inferschema\",\"true\")\\\n",
    "            .csv(os.path.join(\"data\",\"서울시 지하철 호선별 역별 유_무임 승하차 인원 정보.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfd3040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 사용월: integer (nullable = true)\n",
      " |-- 호선명: string (nullable = true)\n",
      " |-- 지하철역: string (nullable = true)\n",
      " |-- 유임승차인원: integer (nullable = true)\n",
      " |-- 무임승차인원: integer (nullable = true)\n",
      " |-- 유임하차인원: integer (nullable = true)\n",
      " |-- 무임하차인원: integer (nullable = true)\n",
      " |-- 작업일자: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf2ed4",
   "metadata": {},
   "source": [
    "* (1-2) 건수를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ace13880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55171"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfc83c",
   "metadata": {},
   "source": [
    "* (1-3) '호선명'별 '유임승차인원'의 순위를 매기고, 그 결과를 30줄 출력 (마지막 'rank' 컬럼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9cbe1641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+------------+------------+------------+------------+--------+----+\n",
      "|사용월|호선명|지하철역|유임승차인원|무임승차인원|유임하차인원|무임하차인원|작업일자|rank|\n",
      "+------+------+--------+------------+------------+------------+------------+--------+----+\n",
      "|201605|일산선|    화정|      515925|      139163|      535460|      142410|20160608|   1|\n",
      "|201512|일산선|    화정|      508044|      136734|      529106|      139931|20160108|   2|\n",
      "|201603|일산선|    화정|      502144|      140596|      526030|      144088|20160408|   3|\n",
      "|201703|일산선|    화정|      499911|      141327|      529944|      145502|20170403|   4|\n",
      "|201510|일산선|    화정|      499388|      520595|      140545|      144148|20151108|   5|\n",
      "|201905|일산선|    화정|      499218|      149790|      520966|      152915|20190603|   6|\n",
      "|201612|일산선|    화정|      497514|      132807|      521734|      136086|20170108|   7|\n",
      "|201805|일산선|    화정|      494994|      139239|      515748|      142997|20180603|   8|\n",
      "|201610|일산선|    화정|      492146|      137462|      513849|      140303|20161108|   9|\n",
      "|201610|일산선|    화정|      492146|      137462|      513849|      140303|20161108|   9|\n",
      "|201912|일산선|    삼송|      491895|      100818|      457339|       99480|20200103|  11|\n",
      "|201712|일산선|    화정|      490937|      127978|      512966|      131552|20180103|  12|\n",
      "|201910|일산선|    화정|      490653|      151951|      508464|      155220|20191103|  13|\n",
      "|201705|일산선|    화정|      490644|      141492|      512873|      145412|20170603|  14|\n",
      "|201803|일산선|    화정|      489304|      137398|      514249|      141440|20180403|  15|\n",
      "|201803|일산선|    화정|      489304|      137398|      514249|      141440|20180403|  15|\n",
      "|201604|일산선|    화정|      485899|      135932|      507461|      139440|20160508|  17|\n",
      "|201709|일산선|    화정|      484872|      139874|      504092|      143148|20171003|  18|\n",
      "|201910|일산선|    삼송|      484643|      105885|      454354|      105185|20191103|  19|\n",
      "|201810|일산선|    화정|      484532|      139895|      509026|      143101|20181103|  20|\n",
      "|201911|일산선|    화정|      483740|      141225|      499920|      143929|20191203|  21|\n",
      "|201511|일산선|    화정|      482906|      505536|      128261|      131672|20151204|  22|\n",
      "|201611|일산선|    화정|      482740|      129876|      508266|      133286|20161208|  23|\n",
      "|201607|일산선|    화정|      482155|      131711|      502448|      134935|20160808|  24|\n",
      "|201811|일산선|    화정|      482071|      132358|      501768|      135435|20181203|  25|\n",
      "|201704|일산선|    화정|      480690|      137811|      502664|      141700|20170503|  26|\n",
      "|201911|일산선|    삼송|      480461|       99525|      450592|       98935|20191203|  27|\n",
      "|201912|일산선|    화정|      480423|      144255|      495808|      147011|20200103|  28|\n",
      "|201606|일산선|    화정|      480161|      134955|      498158|      137884|20160708|  29|\n",
      "|201711|일산선|    화정|      476604|      131931|      500377|      135554|20171203|  30|\n",
      "+------+------+--------+------------+------------+------------+------------+--------+----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "myDf.withColumn(\"rank\", F.rank().over(Window().partitionBy(['호선명']).orderBy(F.col(\"유임승차인원\").desc()))).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81843f83",
   "metadata": {},
   "source": [
    "* (1-4) '호선명'별 '유임승차인원'이 순위가 가장 높은 경우만 30건 출력 (마지막 'rank' 컬럼이 모두 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c23cfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------------+------------+------------+------------+------------+--------+----+\n",
      "|사용월|        호선명|            지하철역|유임승차인원|무임승차인원|유임하차인원|무임하차인원|작업일자|rank|\n",
      "+------+--------------+--------------------+------------+------------+------------+------------+--------+----+\n",
      "|201605|        일산선|                화정|      515925|      139163|      535460|      142410|20160608|   1|\n",
      "|201905|        장항선|                아산|      109243|       12901|       93737|       11808|20190603|   1|\n",
      "|201512|        경부선|              영등포|     1439049|      280623|     1545631|      280969|20160108|   1|\n",
      "|201905|    우이신설선|        북한산보국문|      161867|       45041|      141742|       45814|20190603|   1|\n",
      "|201512|        분당선|                야탑|      769442|      157846|      809197|      156034|20160108|   1|\n",
      "|201512|         7호선|      가산디지털단지|     1245731|       82588|     1243464|       78424|20160108|   1|\n",
      "|201905|        수인선|              인하대|      200474|       28246|      189885|       26442|20190603|   1|\n",
      "|201603|        안산선|              상록수|      632180|       89801|      619361|       90941|20160408|   1|\n",
      "|201512|         4호선|                혜화|     1461258|      138010|     1521596|      138133|20160108|   1|\n",
      "|201501|         1호선|              서울역|     1890411|     1667163|      238403|      220008|20150206|   1|\n",
      "|201703|        경의선|                일산|      257203|       59955|      247634|       60582|20170403|   1|\n",
      "|201712|         3호선|          고속터미널|     1843154|      200178|     1760221|      189058|20180103|   1|\n",
      "|201910|        경강선|            경기광주|      201936|       32028|      186835|       32156|20191103|   1|\n",
      "|201905|        경춘선|            평내호평|      155530|       47748|      155068|       45489|20190603|   1|\n",
      "|201912|         9호선|              신논현|     1063535|       65383|     1095786|       62732|20200103|   1|\n",
      "|201807|    9호선2단계|              봉은사|      452395|       43126|      434135|       40845|20180803|   1|\n",
      "|201710|         6호선|              이태원|      580419|       36941|      680830|       38853|20171103|   1|\n",
      "|201612|         5호선|광화문(세종문화회관)|     1328714|      109907|     1404285|      115604|20170108|   1|\n",
      "|201907|         8호선|                문정|      542664|       57243|      566478|       56677|20190803|   1|\n",
      "|201907|         8호선|                문정|      542664|       57243|      566478|       56677|20190803|   1|\n",
      "|201907|         8호선|                문정|      542664|       57243|      566478|       56677|20190803|   1|\n",
      "|201512|        과천선|                범계|      916951|      111589|      919452|      110456|20160108|   1|\n",
      "|201603|        경인선|                부천|     1173740|      212425|     1160226|      212450|20160408|   1|\n",
      "|201603|        중앙선|                회기|      914516|      135656|      900142|      135321|20160408|   1|\n",
      "|201912|  9호선2~3단계|              봉은사|      613139|       56618|      632524|       53899|20200103|   1|\n",
      "|201501|         2호선|                강남|     3266271|     3353256|      164508|      149186|20150206|   1|\n",
      "|201708|공항철도 1호선|        인천국제공항|      545461|       59577|      508252|       57008|20170903|   1|\n",
      "|201605|        경원선|              의정부|      626917|      130279|      662652|      131349|20160608|   1|\n",
      "+------+--------------+--------------------+------------+------------+------------+------------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.withColumn(\"rank\", F.rank().over(Window().partitionBy(['호선명']).orderBy(F.col(\"유임승차인원\").desc())))\\\n",
    "    .filter(F.col(\"rank\")==1)\\\n",
    "    .show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94dedc9",
   "metadata": {},
   "source": [
    "* (1-5) '호선명'별 '유임승차인원'의 zscore를 계산하고 출력. 윈도우 함수를 사용하여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570cf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "_marksDf = _marksDf.withColumn(\"zscore2\", (F.col('markF')-F.avg('markF').over(byAll))/F.stddev('markF').over(byAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b7e3f",
   "metadata": {},
   "source": [
    "## 문제2: 회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b4348",
   "metadata": {},
   "source": [
    "* sklearn의 make_regression함수를 다음과 같이 사용하여 데이터를 생성하고, 문제를 푸세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11435905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y, coef = make_regression(n_samples = 200,\n",
    "\n",
    "                            n_features = 4,\n",
    "\n",
    "                            n_informative = 3,\n",
    "\n",
    "                            n_targets = 1,\n",
    "\n",
    "                            noise = 0.0,\n",
    "\n",
    "                            coef = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9c9a1",
   "metadata": {},
   "source": [
    "* (2-1) gradient 방법으로 회귀식을 계산하고, 계수를 출력.\n",
    "또한 [식-1]의 'coef'를 출력하고, gradient방법에서 도출된 계수와 일치하는지 비교하세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f15dfcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def computeMSE(a,b,c,d,e,x,y):\n",
    "    totalError = 0\n",
    "    for i in range(0, len(x)):\n",
    "        totalError += (y[i] - (a + b* x[i][0])+ c* x[i][1]+ d* x[i][2]+ e* x[i][3]) ** 2\n",
    "    return totalError / float(len(x))\n",
    "\n",
    "#x: attribute, 1d float array or list\n",
    "#y: class, 1d int array\n",
    "#alpha: learning rate\n",
    "def gradientDescentL(x,y,alpha,iter):\n",
    "    a=random.random()\n",
    "    b=random.random()\n",
    "    c=random.random()\n",
    "    d=random.random()\n",
    "    e=random.random()\n",
    "    alpha=0.001\n",
    "    n=len(x)\n",
    "    for j in range(iter):\n",
    "        aGradient = 0\n",
    "        bGradient = 0\n",
    "        cGradient = 0\n",
    "        dGradient = 0\n",
    "        eGradient = 0\n",
    "        for i in range(n):\n",
    "            aGradient += (2./n) * (((a + b* x[i][0]+ c* x[i][1]+ d* x[i][2]+ e* x[i][3])) - y[i])*(x[i][3])\n",
    "            bGradient += (2./n) * (((a + b* x[i][0]+ c* x[i][1]+ d* x[i][2]+ e* x[i][3])) - y[i])*(x[i][2])\n",
    "            cGradient += (2./n) * (((a + b* x[i][0]+ c* x[i][1]+ d* x[i][2]+ e* x[i][3])) - y[i])*(x[i][1])\n",
    "            dGradient += (2./n) * (((a + b* x[i][0]+ c* x[i][1]+ d* x[i][2]+ e* x[i][3])) - y[i])*(x[i][0])\n",
    "            eGradient += (2./n) * (((a + b* x[i][0]+ c* x[i][1]+ d* x[i][2]+ e* x[i][3])) - y[i])*(1)\n",
    "            \n",
    "            #aGradient += (2./n) * (y[i] - ((a + b * x[i])))*(-1)\n",
    "            #bGradient += (2./n) * (y[i] - ((a + b * x[i])))*(-x[i])\n",
    "        \n",
    "        a = a - (alpha * aGradient)\n",
    "        b = b - (alpha * bGradient)\n",
    "        c = c - (alpha * cGradient)\n",
    "        d = d - (alpha * dGradient)\n",
    "        e = e - (alpha * eGradient)\n",
    "        \n",
    "        if (j%100==0):\n",
    "            print (\"iter:{0} AvgError={1:.3f}\".format(j,computeMSE(a,b,c,d,e,x,y)))\n",
    "    return a,b,c,d,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3053145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0 AvgError=10703.018\n",
      "iter:100 AvgError=13153.058\n",
      "iter:200 AvgError=15812.046\n",
      "iter:300 AvgError=18486.782\n",
      "iter:400 AvgError=21078.030\n",
      "iter:500 AvgError=23550.161\n",
      "iter:600 AvgError=25912.617\n",
      "iter:700 AvgError=28210.152\n",
      "iter:800 AvgError=30520.178\n",
      "iter:900 AvgError=32956.747\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d,e = gradientDescentL(X, y, alpha, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0a7bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=15.623259187794936, b=17.8365854809513, c=67.79566685521836, d=62.13947140029701, e=-17.904549714526702\n",
      "\n",
      "coef:  [55.3360286  83.78717654 39.08701593  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"a={0}, b={1}, c={2}, d={3}, e={4}\\n\".format(a,b,c,d,e))\n",
    "print(\"coef: \",coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7855b5a",
   "metadata": {},
   "source": [
    "* (2-2) 스파크 데이터프레임을 생성 (이후 계속 스파크로 푸세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b81a4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "column_names = ['c1','c2','c3','c4']\n",
    "pDf1 = pd.DataFrame(X, columns = column_names)\n",
    "pDf2 = pd.DataFrame(y, columns = ['label'])\n",
    "pDf = pd.concat([pDf1,pDf2],axis = 1)\n",
    "myDf = spark.createDataFrame(pDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a55e93ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+--------------------+-------------------+\n",
      "|                  c1|                 c2|                  c3|                  c4|              label|\n",
      "+--------------------+-------------------+--------------------+--------------------+-------------------+\n",
      "| -0.5512403857978609|-0.5965031205554089|-0.03364710408861073|-0.29776578515002167| -81.79793091627283|\n",
      "|  0.1480724023308886| 1.3696862884074434|-0.06062070640317007|  0.6074273918565379| 120.58640302306809|\n",
      "|0.013323315921294604|-0.0932709415354416|   1.085331164129407|  0.9385017786465617|  35.34470705162554|\n",
      "| -0.5902230222526916| 1.8676691134617172|  2.8052006040792103| -0.6826307783894384|  233.4730443928036|\n",
      "|  0.7265051462610764| -1.669587779785849| -1.2191792912549058|  1.4481460981561571|-147.34221688232523|\n",
      "|  0.9183160600969698|-1.0090764786305508|   1.509863487999698|-0.22673783247861345| 25.284352922658954|\n",
      "|-0.13428669127646833|-0.5835265175464377| -0.4869485731192414| -1.0240920131176738| -75.35629816618875|\n",
      "|  0.8463305183661116|-1.3163820814532865| -0.6227365501109313| -1.0119813858317925| -87.80428153729879|\n",
      "| 0.29067263199963705| 0.9458726932899222| -0.8044850918678604|  1.7533127573359155|  63.89174981007628|\n",
      "|  1.7328929024551039|-1.9367490536803793| -2.0464383256478453| -0.7660198459235262| -146.3724910999654|\n",
      "|0.017052833690232742|-0.6910554665142883|  1.3342749669197826| 0.22921829728326576|-4.8051233869247625|\n",
      "|  0.3537892433433613|  1.991789416990606| 0.36898687484425335| 0.15122877281442637| 200.88629905432796|\n",
      "| 0.35128744612767765|  1.943735881112389|  0.5533567651507133| 0.07782873571956515| 203.92805827811037|\n",
      "|-0.40991121756799825|0.29568436041843355|  0.9871612261516893| 0.28396404413089643|    40.676885422071|\n",
      "|  1.2003974548633836|-0.8598337656286655| -0.6577517671664747|-0.04492699166868394|-31.327369422948806|\n",
      "|   1.091150773232776|-1.4616547724921518|0.007314363810284...|-0.10738237535765119| -61.80207941101897|\n",
      "|   0.864856186075065| -1.342169621853863| 0.06001446105647297|  -0.888683646962293|-62.253110207239935|\n",
      "| -0.7679802749325663| 0.8504374813721925| -1.2247598145742717|-0.24432341366228127|-19.113429458454718|\n",
      "| -0.2184028081500972| 1.7186273165086556| -0.2576753051425686| 0.35571151137192575|  121.8416275767805|\n",
      "|  -1.367388995282321|  0.590548831515639| -1.1921060275553232|  1.0002995926244747| -72.78132464407022|\n",
      "+--------------------+-------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753509b",
   "metadata": {},
   "source": [
    "* (2-3) 훈련, 테스트 데이터를 6:4 비율로 분리하고,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4f341eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDf: 116, testDf: 84\n"
     ]
    }
   ],
   "source": [
    "(trainDf, testDf) = myDf.randomSplit([0.6,0.4])\n",
    "print(\"trainDf: {}, testDf: {}\".format(trainDf.count(), testDf.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2ca066b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[c1: double, c2: double, c3: double, c4: double, label: double]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f8f88",
   "metadata": {},
   "source": [
    "* (2-4) 회귀모델링하고 계수와 절편 출력. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d605607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "va = VectorAssembler(inputCols = [\"c1\",\"c2\",\"c3\",\"c4\"],\n",
    "                                   outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "92ff075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='label', maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "22613835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[va, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e9eaf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainDf)\n",
    "modelTrainDf = model.transform(trainDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ce60d4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [55.00133172771247,83.49451353486926,38.853993265201375,0.0]\n",
      "Intercept: 0.024\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: {}\".format(model.stages[-1].coefficients))\n",
    "print(\"Intercept: {:.3f}\".format(model.stages[-1].intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "49709b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|              label|         prediction|\n",
      "+-------------------+-------------------+\n",
      "| -241.6841454869239| -240.3167474512355|\n",
      "|-217.01780831752205| -215.8120855419073|\n",
      "| -7.822469937755862| -7.627551789559692|\n",
      "| -48.39870580667795|-47.761582061913764|\n",
      "|-144.16434072579023|-143.42221578964248|\n",
      "|  90.17808404484983|  89.95528082401484|\n",
      "| -164.0553757050139| -163.2867671673788|\n",
      "| -1.195234751855196|-1.0431309036502148|\n",
      "| -54.69345936658635|-54.297835869381494|\n",
      "| -96.28753259921422| -95.84630430737563|\n",
      "+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelTrainDf.select('label','prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7145a6",
   "metadata": {},
   "source": [
    "* (2-5) 테스트 데이터에 대해 R2를 구해서 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b6573845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1f7ea88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r2: 1.000'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"r2: {evaluator.evaluate(modelTestDf):.3f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d9e433",
   "metadata": {},
   "source": [
    "## 문제3: 텍스트 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664358c",
   "metadata": {},
   "source": [
    "* (3-1) 데이터프레임을 생성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f29a9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+----------------------------------+\n",
      "|cls|                               pos|                               neg|\n",
      "+---+----------------------------------+----------------------------------+\n",
      "|0.0|        진짜 꼭 보세요 최고의 영화| 고구마 먹은 영화 유치해서 못보...|\n",
      "|0.0|  엔드게임 이후 마블이 한 번 더...|  노잼이네요.. 왜 배우들이 출연...|\n",
      "|0.0| 정말 오랜만에 감동 울었네... 펑펑|   제발 뻘짓 좀 그만하셨으면......|\n",
      "|0.0|연출에서 등장인물 하나하나의 아...| 스토리가 매우 매우 아쉽다 지루...|\n",
      "|0.0|어렸을때는 그냥 액션과 화려함에...|             영화 약간 이해가 안됨|\n",
      "|0.0|               꼭 보세여 넘 재밌어|좋아하는 배우들인데 최근 영화라...|\n",
      "|0.0| 어릴적 영화관에서 처음으로 본 ...| 그지같네 도대체 이 따위 영화를...|\n",
      "|0.0|올해 본 영화 중 최고의 영화입니다.|  스크린보다 시계를 더 많이 봄....|\n",
      "|0.0|  극장에서 보는 거 적극 추천 최고!| 이때까지 본 영화중에 제일 최악...|\n",
      "|0.0|    인생영화이고 평생 못잊을거같다|    나만 짜증.. 줄거리 한줄평.....|\n",
      "|0.0|  그냥 진짜 재밌어 진짜 잘 만든...|로맨틱 코미디로 방향을 잡았으면...|\n",
      "|0.0|  자연과 인간, 아버지와 아들 등...| 똥 싸다가 막힌 느낌 안보는거를...|\n",
      "|0.0|진정한 아름다움은 완벽이 아니라...|  어우 핵노잼 영화가 왜 이렇게 ...|\n",
      "|0.0|                띵작입니다 ㄹㅇ!!!| 솔직히 재미없음 감독이 뭘 말할...|\n",
      "|0.0|        감동 그 자체 스파이더맨 짱| 어설픈 연출력 어설픈 결말 현실...|\n",
      "|0.0| 최고입니다. 여운이 가시지가 않...|뭘 말하고싶은지 모르겠다 아쉽다...|\n",
      "|0.0| 단언컨대 한국 최고의 영화 복수...| 새벽에 케이블에서 볼거 없어서 ...|\n",
      "|0.0| 그냥 대박임 그 시절 스파이더맨...|         핵노잼 억지 착한척 오졌다|\n",
      "|0.0| 다음 날 새벽 출근임에도 불구하...|오그라드는 대사는 기본에 옵션으...|\n",
      "|0.0|           최고중 최고 진짜 베스트| 역대급 호화캐스팅인데 스토리, ...|\n",
      "+---+----------------------------------+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_tRdd=spark.sparkContext\\\n",
    "    .textFile(os.path.join('data','review2.txt'))\n",
    "\n",
    "trdd = _tRdd.map(lambda x: x.split('|')).map(lambda x:[float(x[0]),x[1], x[2]])\n",
    "myDf2 = spark.createDataFrame(trdd, ['cls','pos','neg'])\n",
    "\n",
    "myDf2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998befa",
   "metadata": {},
   "source": [
    "* (3-2) 불용어 제거, 불필요 단어 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cea91fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+----------------------------------+----------------------------------+--------------------------------+\n",
      "|cls|                               pos|                               neg|                            posRex|                          negRex|\n",
      "+---+----------------------------------+----------------------------------+----------------------------------+--------------------------------+\n",
      "|0.0|        진짜 꼭 보세요 최고의 영화| 고구마 먹은 영화 유치해서 못보...|     [진짜, 꼭, 보세요, 최고의,...|  [고구마, 먹은, 영화, 유치해...|\n",
      "|0.0|  엔드게임 이후 마블이 한 번 더...|  노잼이네요.. 왜 배우들이 출연...|    [엔드게임, 이후, 마블이, 한...|  [노잼이네요.., 왜, 배우들이...|\n",
      "|0.0| 정말 오랜만에 감동 울었네... 펑펑|   제발 뻘짓 좀 그만하셨으면......|    [정말, 오랜만에, 감동, 울었...|  [제발, 뻘짓, 좀, 그만하셨으...|\n",
      "|0.0|연출에서 등장인물 하나하나의 아...| 스토리가 매우 매우 아쉽다 지루...|  [연출에서, 등장인물, 하나하나...|  [스토리가, 매우, 매우, 아쉽...|\n",
      "|0.0|어렸을때는 그냥 액션과 화려함에...|             영화 약간 이해가 안됨|    [어렸을때는, 그냥, 액션과, ...|      [영화, 약간, 이해가, 안됨]|\n",
      "|0.0|               꼭 보세여 넘 재밌어|좋아하는 배우들인데 최근 영화라...|          [꼭, 보세여, 넘, 재밌어]| [좋아하는, 배우들인데, 최근,...|\n",
      "|0.0| 어릴적 영화관에서 처음으로 본 ...| 그지같네 도대체 이 따위 영화를...|  [어릴적, 영화관에서, 처음으로...|  [그지같네, 도대체, 이, 따위...|\n",
      "|0.0|올해 본 영화 중 최고의 영화입니다.|  스크린보다 시계를 더 많이 봄....|      [올해, 본, 영화, 중, 최고...|  [스크린보다, 시계를, 더, 많...|\n",
      "|0.0|  극장에서 보는 거 적극 추천 최고!| 이때까지 본 영화중에 제일 최악...|     [극장에서, 보는, 거, 적극,...|  [이때까지, 본, 영화중에, 제...|\n",
      "|0.0|    인생영화이고 평생 못잊을거같다|    나만 짜증.. 줄거리 한줄평.....|[인생영화이고, 평생, 못잊을거같다]|    [나만, 짜증.., 줄거리, 한...|\n",
      "|0.0|  그냥 진짜 재밌어 진짜 잘 만든...|로맨틱 코미디로 방향을 잡았으면...|     [그냥, 진짜, 재밌어, 진짜,...|  [로맨틱, 코미디로, 방향을, ...|\n",
      "|0.0|  자연과 인간, 아버지와 아들 등...| 똥 싸다가 막힌 느낌 안보는거를...|     [자연과, 인간,, 아버지와, ...|    [똥, 싸다가, 막힌, 느낌, ...|\n",
      "|0.0|진정한 아름다움은 완벽이 아니라...|  어우 핵노잼 영화가 왜 이렇게 ...|   [진정한, 아름다움은, 완벽이,...|   [어우, 핵노잼, 영화가, 왜,...|\n",
      "|0.0|                띵작입니다 ㄹㅇ!!!| 솔직히 재미없음 감독이 뭘 말할...|             [띵작입니다, ㄹㅇ!!!]|  [솔직히, 재미없음, 감독이, ...|\n",
      "|0.0|        감동 그 자체 스파이더맨 짱| 어설픈 연출력 어설픈 결말 현실...|    [감동, 그, 자체, 스파이더맨...|  [어설픈, 연출력, 어설픈, 결...|\n",
      "|0.0| 최고입니다. 여운이 가시지가 않...|뭘 말하고싶은지 모르겠다 아쉽다...|   [최고입니다., 여운이, 가시지...| [뭘, 말하고싶은지, 모르겠다,...|\n",
      "|0.0| 단언컨대 한국 최고의 영화 복수...| 새벽에 케이블에서 볼거 없어서 ...|    [단언컨대, 한국, 최고의, 영...|  [새벽에, 케이블에서, 볼거, ...|\n",
      "|0.0| 그냥 대박임 그 시절 스파이더맨...|         핵노잼 억지 착한척 오졌다|      [그냥, 대박임, 그, 시절, ...|  [핵노잼, 억지, 착한척, 오졌다]|\n",
      "|0.0| 다음 날 새벽 출근임에도 불구하...|오그라드는 대사는 기본에 옵션으...|    [다음, 날, 새벽, 출근임에도...| [오그라드는, 대사는, 기본에,...|\n",
      "|0.0|           최고중 최고 진짜 베스트| 역대급 호화캐스팅인데 스토리, ...|      [최고중, 최고, 진짜, 베스트]|[역대급, 호화캐스팅인데, 스토...|\n",
      "+---+----------------------------------+----------------------------------+----------------------------------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "regexTok = RegexTokenizer(inputCol = 'pos',outputCol = 'posRex', pattern=\"\\\\s+\")\n",
    "_tokDf = regexTok.transform(myDf2)\n",
    "\n",
    "regexTok = RegexTokenizer(inputCol = 'neg',outputCol = 'negRex', pattern=\"\\\\s+\")\n",
    "_tokDf = regexTok.transform(_tokDf)\n",
    "_tokDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a3beb570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "import re\n",
    "\n",
    "def trim(wordList):\n",
    "    regex = re.compile('\\d+')\n",
    "    cleaned = list()\n",
    "    for w in wordList:\n",
    "        if not regex.match(w):\n",
    "            cleaned.append(w.lstrip('‘').rstrip('’').rstrip('.').rstrip(',').replace(\"'\",\"\").replace('\"','').replace(\"(\",\"\").replace(\")\",\"\"))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d25269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
